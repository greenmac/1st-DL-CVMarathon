{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 使用Xception backbone做 Trnasfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解如何使用Transfer Learning\n",
    "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 可以自行嘗試多種架構"
   ]
  },
  {
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Input\n",
    " \n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "#include top 決定要不要加入 fully Connected Layer\n",
    "\n",
    "# 參考 https://keras.io/zh/applications/\n",
    "'''Xception 架構'''\n",
    "model = keras.applications.xception.Xception(include_top=False, weights='imagenet',\n",
    "                                    input_tensor=input_tensor,\n",
    "                                    pooling=None, classes=10)\n",
    "# '''Resnet 50 架構'''\n",
    "#model=keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
    "                                    #input_tensor=input_tensor,\n",
    "                                    #pooling=None, classes=10)\n",
    "model.summary()\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "                 \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n                                                                 add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_11[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 1, 1, 1024)   745472      add_11[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 1, 1, 1024)   4096        conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_12[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 20,806,952\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n"
    }
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加層數"
   ]
  },
  {
   "source": [
    "x = model.output\n",
    "\n",
    "'''可以參考Cifar10實作章節'''\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(p=0.1)(x)\n",
    "\n",
    "predictions = Dense(output_dim=10,activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "print('Model深度：', len(model.layers))\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model深度： 136\nC:\\Users\\alway\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n  \nC:\\Users\\alway\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n  \n"
    }
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鎖定特定幾層不要更新權重"
   ]
  },
  {
   "source": [
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備 Cifar 10 資料"
   ]
  },
  {
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(50000, 32, 32, 3)\n"
    }
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=100)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n50000/50000 [==============================] - 998s 20ms/step - loss: 1.4224 - accuracy: 0.4972\nEpoch 2/100\n50000/50000 [==============================] - 1049s 21ms/step - loss: 1.0280 - accuracy: 0.6473\nEpoch 3/100\n50000/50000 [==============================] - 1059s 21ms/step - loss: 0.9143 - accuracy: 0.6858\nEpoch 4/100\n50000/50000 [==============================] - 1045s 21ms/step - loss: 0.8233 - accuracy: 0.7159\nEpoch 5/100\n50000/50000 [==============================] - 1049s 21ms/step - loss: 0.7460 - accuracy: 0.7426\nEpoch 6/100\n50000/50000 [==============================] - 996s 20ms/step - loss: 0.6859 - accuracy: 0.7647\nEpoch 7/100\n50000/50000 [==============================] - 981s 20ms/step - loss: 0.6133 - accuracy: 0.7890\nEpoch 8/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.5508 - accuracy: 0.8100\nEpoch 9/100\n50000/50000 [==============================] - 995s 20ms/step - loss: 0.4989 - accuracy: 0.8286\nEpoch 10/100\n50000/50000 [==============================] - 1036s 21ms/step - loss: 0.4524 - accuracy: 0.8450\nEpoch 11/100\n50000/50000 [==============================] - 1051s 21ms/step - loss: 0.4150 - accuracy: 0.8579\nEpoch 12/100\n50000/50000 [==============================] - 1105s 22ms/step - loss: 0.3752 - accuracy: 0.8704\nEpoch 13/100\n50000/50000 [==============================] - 1070s 21ms/step - loss: 0.3478 - accuracy: 0.8802\nEpoch 14/100\n50000/50000 [==============================] - 916s 18ms/step - loss: 0.3245 - accuracy: 0.8890\nEpoch 15/100\n50000/50000 [==============================] - 995s 20ms/step - loss: 0.3022 - accuracy: 0.8957\nEpoch 16/100\n50000/50000 [==============================] - 1004s 20ms/step - loss: 0.2779 - accuracy: 0.9037\nEpoch 17/100\n50000/50000 [==============================] - 995s 20ms/step - loss: 0.2668 - accuracy: 0.9092\nEpoch 18/100\n50000/50000 [==============================] - 981s 20ms/step - loss: 0.2502 - accuracy: 0.9154\nEpoch 19/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.2414 - accuracy: 0.9178\nEpoch 20/100\n50000/50000 [==============================] - 972s 19ms/step - loss: 0.2251 - accuracy: 0.9237\nEpoch 21/100\n50000/50000 [==============================] - 975s 20ms/step - loss: 0.2182 - accuracy: 0.9270\nEpoch 22/100\n50000/50000 [==============================] - 973s 19ms/step - loss: 0.2117 - accuracy: 0.9272\nEpoch 23/100\n50000/50000 [==============================] - 969s 19ms/step - loss: 0.1956 - accuracy: 0.9336\nEpoch 24/100\n50000/50000 [==============================] - 969s 19ms/step - loss: 0.1984 - accuracy: 0.9319\nEpoch 25/100\n50000/50000 [==============================] - 1025s 20ms/step - loss: 0.1848 - accuracy: 0.9385\nEpoch 26/100\n50000/50000 [==============================] - 1035s 21ms/step - loss: 0.1768 - accuracy: 0.9422\nEpoch 27/100\n50000/50000 [==============================] - 997s 20ms/step - loss: 0.1770 - accuracy: 0.9396\nEpoch 28/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1679 - accuracy: 0.9437\nEpoch 29/100\n50000/50000 [==============================] - 964s 19ms/step - loss: 0.1614 - accuracy: 0.9460\nEpoch 30/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.1589 - accuracy: 0.9468\nEpoch 31/100\n50000/50000 [==============================] - 967s 19ms/step - loss: 0.1584 - accuracy: 0.9471\nEpoch 32/100\n50000/50000 [==============================] - 969s 19ms/step - loss: 0.1525 - accuracy: 0.9478\nEpoch 33/100\n50000/50000 [==============================] - 964s 19ms/step - loss: 0.1503 - accuracy: 0.9488\nEpoch 34/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.1427 - accuracy: 0.9521\nEpoch 35/100\n50000/50000 [==============================] - 962s 19ms/step - loss: 0.1427 - accuracy: 0.9521\nEpoch 36/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1320 - accuracy: 0.9552\nEpoch 37/100\n50000/50000 [==============================] - 964s 19ms/step - loss: 0.1332 - accuracy: 0.9554\nEpoch 38/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.1296 - accuracy: 0.9564\nEpoch 39/100\n50000/50000 [==============================] - 968s 19ms/step - loss: 0.1253 - accuracy: 0.9569\nEpoch 40/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1253 - accuracy: 0.9585\nEpoch 41/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1227 - accuracy: 0.9591\nEpoch 42/100\n50000/50000 [==============================] - 963s 19ms/step - loss: 0.1231 - accuracy: 0.9593\nEpoch 43/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1170 - accuracy: 0.9604\nEpoch 44/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.1172 - accuracy: 0.9609\nEpoch 45/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1125 - accuracy: 0.9621\nEpoch 46/100\n50000/50000 [==============================] - 967s 19ms/step - loss: 0.1136 - accuracy: 0.9630\nEpoch 47/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1114 - accuracy: 0.9632\nEpoch 48/100\n50000/50000 [==============================] - 964s 19ms/step - loss: 0.1097 - accuracy: 0.9630\nEpoch 49/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.1063 - accuracy: 0.9648\nEpoch 50/100\n50000/50000 [==============================] - 963s 19ms/step - loss: 0.1067 - accuracy: 0.9658\nEpoch 51/100\n50000/50000 [==============================] - 968s 19ms/step - loss: 0.1036 - accuracy: 0.9653\nEpoch 52/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.1016 - accuracy: 0.9668\nEpoch 53/100\n50000/50000 [==============================] - 967s 19ms/step - loss: 0.0986 - accuracy: 0.9677\nEpoch 54/100\n50000/50000 [==============================] - 968s 19ms/step - loss: 0.1011 - accuracy: 0.9674\nEpoch 55/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.0964 - accuracy: 0.9679\nEpoch 56/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.0980 - accuracy: 0.9682\nEpoch 57/100\n50000/50000 [==============================] - 963s 19ms/step - loss: 0.0962 - accuracy: 0.9688\nEpoch 58/100\n50000/50000 [==============================] - 965s 19ms/step - loss: 0.0937 - accuracy: 0.9700\nEpoch 59/100\n50000/50000 [==============================] - 976s 20ms/step - loss: 0.0885 - accuracy: 0.9708\nEpoch 60/100\n50000/50000 [==============================] - 962s 19ms/step - loss: 0.0886 - accuracy: 0.9711\nEpoch 61/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.0914 - accuracy: 0.9700\nEpoch 62/100\n50000/50000 [==============================] - 968s 19ms/step - loss: 0.0920 - accuracy: 0.9705\nEpoch 63/100\n50000/50000 [==============================] - 966s 19ms/step - loss: 0.0867 - accuracy: 0.9714\nEpoch 64/100\n50000/50000 [==============================] - 975s 20ms/step - loss: 0.0876 - accuracy: 0.9716\nEpoch 65/100\n50000/50000 [==============================] - 1007s 20ms/step - loss: 0.0865 - accuracy: 0.9714\nEpoch 66/100\n50000/50000 [==============================] - 1003s 20ms/step - loss: 0.0897 - accuracy: 0.9716\nEpoch 67/100\n50000/50000 [==============================] - 1019s 20ms/step - loss: 0.0807 - accuracy: 0.9735\nEpoch 68/100\n35872/50000 [====================>.........] - ETA: 4:42 - loss: 0.0786 - accuracy: 0.9748"
    }
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}